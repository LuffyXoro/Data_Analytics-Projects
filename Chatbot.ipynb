{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee20aec5-7e6c-4a0f-976f-39d3b2ec6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125d6b9-ca8f-4e47-8b98-7703a9ead702",
   "metadata": {},
   "source": [
    "# Read Data & create a list of your columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6cc18-bd73-4868-96dd-2b7dbca11e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30591d55-8694-4944-9c93-07f19e3aef77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Data Analytics ?</td>\n",
       "      <td>Data analytics is the process of analyzing raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does this project do ?</td>\n",
       "      <td>This is a chat-bot based on cosine  simarilari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Questions   \\\n",
       "0     What is Data Analytics ?   \n",
       "1  What does this project do ?   \n",
       "\n",
       "                                             Answers  \n",
       "0  Data analytics is the process of analyzing raw...  \n",
       "1  This is a chat-bot based on cosine  simarilari...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33adde93-02ec-447f-aae1-3149be7fc281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Questions ', 'Answers'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d5dcf1-d34e-4cd6-bca4-3c9e7fc10d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list=df['Answers'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24873fbe-deaf-45c3-b178-7ac40c582093",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list=df['Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a824c744-3b95-45fd-b7d5-ffd7f311db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data analytics is the process of analyzing raw data to find trends and answer questions.', 'This is a chat-bot based on cosine  simarilarity with the integration of data anlytics which answers your question.']\n"
     ]
    }
   ],
   "source": [
    "print(answers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc76696-30c1-4504-b72d-95d0ca261d61",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d8c51d-9cac-4661-8bd3-0ffdc2c469f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in e:\\anaconda3\\envs\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in e:\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in e:\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\envs\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\RUDRA\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\RUDRA\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\RUDRA\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\RUDRA\n",
      "[nltk_data]     SINGH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f61ecb-2416-43b7-90a9-4e6e089eaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stemmer=PorterStemmer()\n",
    "    text=re.sub(r'[^\\w\\s]','',text) # Remove non-alphanumeric charaters \n",
    "\n",
    "    tokens=nltk.word_tokenize(text.lower())\n",
    "    tokens=[token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(token) for token in tokens]\n",
    "    stemmed_tokens=[stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58e1e80-c8e6-401f-8f59-a6495f7959d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_with_stopwords(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dca6c5e-7b37-419a-a1bf-7a97a33ccba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize,token_pattern=None)\n",
    "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22d490ec-2556-4646-9d19-eda475f05465",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a8382e-5a7d-44a4-b3d4-c31bcc785abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text: data analytics\n",
      "similarities: [[0.70710678 0.        ]]\n",
      "max_similarity: 0.7071067811865476\n",
      "high_similarity_questions: ['What is Data Analytics ?']\n",
      "['Data analytics is the process of analyzing raw data to find trends and answer questions.']\n",
      "processed_text_with_stopwords: data analytics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data analytics is the process of analyzing raw data to find trends and answer questions.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize,token_pattern=None)\n",
    "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
    "\n",
    "def get_response(text):\n",
    "    processed_text = preprocess_with_stopwords(text)\n",
    "    print(\"processed_text:\", processed_text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    similarities = cosine_similarity(vectorized_text, X)\n",
    "    print(\"similarities:\", similarities)\n",
    "    max_similarity = np.max(similarities)\n",
    "    print(\"max_similarity:\", max_similarity)\n",
    "    if max_similarity > 0.6:\n",
    "        high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
    "        print(\"high_similarity_questions:\", high_similarity_questions)\n",
    "\n",
    "        target_answers=[]\n",
    "        for q in high_similarity_questions:\n",
    "            q_index=questions_list.index(q)\n",
    "            target_answers.append(answers_list[q_index])\n",
    "        print(target_answers)\n",
    "\n",
    "        Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
    "        processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
    "        print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
    "        vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
    "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
    "        closest = np.argmax(final_similarities)\n",
    "        return target_answers[closest]\n",
    "    else:\n",
    "        return \"I can't answer this question.\"\n",
    "\n",
    "get_response('What is data analytics?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a1117-8477-4b02-925f-cc211b915bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3fc2d-5bda-428c-85f4-a0376199e520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f324c-0133-4ecb-97d6-a02795d22a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
